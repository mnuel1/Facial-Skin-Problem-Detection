import numpy as np
import tensorflow as tf
from keras import Model
from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout


from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import os
from PIL import Image


def load_custom_dataset():

    image_paths = []
    labels = []

    # Create a dictionary to map class names to integer labels
    class_to_label = {}
    label_counter = 0

    # Iterate through the subfolders in the image folder, assuming each subfolder represents a class
    for class_folder in os.listdir('datasets/Dataset/train'):
        class_path = os.path.join('datasets/Dataset/train', class_folder)
        if os.path.isdir(class_path):
            class_to_label[class_folder] = label_counter
            label_counter += 1

            for image_file in os.listdir(class_path):
                if image_file.endswith(".jpg"):  # You can adjust the file format
                    image_path = os.path.join(class_path, image_file)
                    image_paths.append(image_path)
                    labels.append(class_folder)
                    
    # Convert labels to integers using the class_to_label dictionary
    y = np.array([class_to_label[label] for label in labels])

    # Split the dataset into training and test sets (80% training, 20% test)
    X_train, X_test, y_train, y_test = train_test_split(image_paths, y, test_size=0.2, random_state=42)

    return (np.array(X_train), np.array(y_train)), (np.array(X_test), np.array(y_test))

# Load and preprocess images from file paths
def load_and_preprocess_images(image_paths, target_size=(294, 222)):
    images = []
    for image_path in image_paths:
        image = Image.open(image_path)
        
        # Resize the image to the target size    
        image = image.resize(target_size)

        # Convert to NumPy array and normalize pixel values
        image = np.array(image) / 255.0
       
        images.append(image)
    return np.array(images)

# Define class names for your custom dataset
class_names = ['Acne and Rosacea Photos', 
               'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', 'Atopic Dermatitis Photos', 'Bullous Disease Photos', 'Cellulitis Impetigo and other Bacterial Infections', 'Eczema Photos', 'Exanthems and Drug Eruptions', 'Hair Loss Photos Alopecia and other Hair Diseases', 'Herpes HPV and other STDs Photos', 'Light Diseases and Disorders of Pigmentation', 'Lupus and other Connective Tissue diseases', 'Melanoma Skin Cancer Nevi and Moles', 'Nail Fungus and other Nail Disease', 'Poison Ivy Photos and other Contact Dermatitis', 'Psoriasis pictures Lichen Planus and related diseases', 'Scabies Lyme Disease and other Infestations and Bites', 'Seborrheic Keratoses and other Benign Tumors', 'Systemic Disease', 'Tinea Ringworm Candidiasis and other Fungal Infections', 'Urticaria Hives', 'Vascular Tumors', 'Vasculitis Photos', 'Warts Molluscum and other Viral Infections']

# Function to display images with integer labels
def display_images_with_labels(image_paths, labels, class_names, num_images=25):
    plt.figure(figsize=(10, 10))
    for i in range(min(num_images, len(image_paths))):
        plt.subplot(5, 5, i + 1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)

        # Load and display the image
        image = Image.open(image_paths[i])
        plt.imshow(image)
        
        # Display the integer label
        label = labels[i]
        if label >= 0 and label < len(class_names):  # Check if the label is within the valid range
            class_name = class_names[label]
            plt.xlabel(f"({class_name})")
        else:
            plt.xlabel(f"(Invalid)")

    plt.show()

# Load your custom dataset with integer labels
(train_images, train_labels), (test_images, test_labels) = load_custom_dataset()

# Resize and preprocess train images to match the model's input shape
X_train = load_and_preprocess_images(train_images, target_size=(294, 222))

# Resize and preprocess test images to match the model's input shape
X_test = load_and_preprocess_images(test_images, target_size=(294, 222))

# Display some images from your custom dataset
# display_images_with_labels(train_images, train_labels, class_names)

# Define the input shape
input_shape = (294, 222, 3)  # Adjust the input size as needed

# Input layer
inputs = Input(shape=input_shape)

# Convolutional layers
x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
x = MaxPooling2D((2, 2))(x)
x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D((2, 2))(x)
x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D((2, 2))(x)

# Flatten layer
x = Flatten()(x)

# Fully connected layers
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)  # Dropout for regularization
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)

# Output layer with binary classification (1 neuron, sigmoid activation)
outputs = Dense(1, activation='sigmoid')(x)

# Create the model
model = Model(inputs=inputs, outputs=outputs)

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',  # Binary cross-entropy for binary classification
              metrics=['accuracy'])

history = model.fit(X_train, train_labels, epochs=10, validation_data=(X_test, test_labels))

plt.figure(figsize=(10, 10))
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(X_test, test_labels, verbose=2)
plt.show()
print(test_acc)

# Save the entire model to a file
model.save("my_model.h5")
